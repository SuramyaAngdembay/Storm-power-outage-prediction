{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6c8711-e149-4656-b5cc-b5e017e43b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201402</td>\n",
       "      <td>18</td>\n",
       "      <td>1000</td>\n",
       "      <td>201402</td>\n",
       "      <td>18</td>\n",
       "      <td>2000</td>\n",
       "      <td>83473</td>\n",
       "      <td>503953</td>\n",
       "      <td>NEW HAMPSHIRE</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low pressure developing south of Long Island a...</td>\n",
       "      <td>Eight to twelve inches of snow fell across eas...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201403</td>\n",
       "      <td>30</td>\n",
       "      <td>831</td>\n",
       "      <td>201403</td>\n",
       "      <td>30</td>\n",
       "      <td>931</td>\n",
       "      <td>83971</td>\n",
       "      <td>507163</td>\n",
       "      <td>MASSACHUSETTS</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>CHELMSFORD CENTER</td>\n",
       "      <td>42.5861</td>\n",
       "      <td>-71.3472</td>\n",
       "      <td>42.5867</td>\n",
       "      <td>-71.3469</td>\n",
       "      <td>A stacked low pressure system passed south and...</td>\n",
       "      <td>Boston Road was closed near Brian Road due to ...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201404</td>\n",
       "      <td>27</td>\n",
       "      <td>2306</td>\n",
       "      <td>201404</td>\n",
       "      <td>27</td>\n",
       "      <td>2306</td>\n",
       "      <td>83517</td>\n",
       "      <td>506236</td>\n",
       "      <td>MISSOURI</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>W</td>\n",
       "      <td>AVA</td>\n",
       "      <td>36.9500</td>\n",
       "      <td>-92.6600</td>\n",
       "      <td>36.9500</td>\n",
       "      <td>-92.6600</td>\n",
       "      <td>A powerful storm system and a dry line produce...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201404</td>\n",
       "      <td>27</td>\n",
       "      <td>2303</td>\n",
       "      <td>201404</td>\n",
       "      <td>27</td>\n",
       "      <td>2303</td>\n",
       "      <td>83517</td>\n",
       "      <td>506237</td>\n",
       "      <td>MISSOURI</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>W</td>\n",
       "      <td>AVA</td>\n",
       "      <td>36.9500</td>\n",
       "      <td>-92.6600</td>\n",
       "      <td>36.9500</td>\n",
       "      <td>-92.6600</td>\n",
       "      <td>A powerful storm system and a dry line produce...</td>\n",
       "      <td>Several power poles snapped and trees blown down.</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201402</td>\n",
       "      <td>15</td>\n",
       "      <td>1300</td>\n",
       "      <td>201402</td>\n",
       "      <td>15</td>\n",
       "      <td>2100</td>\n",
       "      <td>83132</td>\n",
       "      <td>501499</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A strong cold front produced strong winds for ...</td>\n",
       "      <td>Two stations measured strong wind gusts in the...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>201403</td>\n",
       "      <td>6</td>\n",
       "      <td>1400</td>\n",
       "      <td>201403</td>\n",
       "      <td>7</td>\n",
       "      <td>1300</td>\n",
       "      <td>83831</td>\n",
       "      <td>506449</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>SSE</td>\n",
       "      <td>SHAWMUT</td>\n",
       "      <td>46.4838</td>\n",
       "      <td>-109.6059</td>\n",
       "      <td>45.5450</td>\n",
       "      <td>-109.2083</td>\n",
       "      <td>After a very cold winter resulting in area riv...</td>\n",
       "      <td>County officials and the Montana Department of...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>201403</td>\n",
       "      <td>6</td>\n",
       "      <td>1400</td>\n",
       "      <td>201403</td>\n",
       "      <td>7</td>\n",
       "      <td>1300</td>\n",
       "      <td>83831</td>\n",
       "      <td>506451</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>ESE</td>\n",
       "      <td>GREYCLIFF</td>\n",
       "      <td>46.4838</td>\n",
       "      <td>-109.6059</td>\n",
       "      <td>45.5450</td>\n",
       "      <td>-109.2083</td>\n",
       "      <td>After a very cold winter resulting in area riv...</td>\n",
       "      <td>County officials and the Montana Department of...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>201403</td>\n",
       "      <td>9</td>\n",
       "      <td>1800</td>\n",
       "      <td>201403</td>\n",
       "      <td>11</td>\n",
       "      <td>1330</td>\n",
       "      <td>83831</td>\n",
       "      <td>512872</td>\n",
       "      <td>MONTANA</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>ESE</td>\n",
       "      <td>PARK CITY</td>\n",
       "      <td>45.4200</td>\n",
       "      <td>-109.3844</td>\n",
       "      <td>45.5376</td>\n",
       "      <td>-108.3358</td>\n",
       "      <td>After a very cold winter resulting in area riv...</td>\n",
       "      <td>County officials reported that some streams an...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>201404</td>\n",
       "      <td>7</td>\n",
       "      <td>1115</td>\n",
       "      <td>201404</td>\n",
       "      <td>7</td>\n",
       "      <td>1315</td>\n",
       "      <td>83926</td>\n",
       "      <td>508171</td>\n",
       "      <td>MISSISSIPPI</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>WILLIAMSVILLE</td>\n",
       "      <td>32.7600</td>\n",
       "      <td>-89.1400</td>\n",
       "      <td>32.7611</td>\n",
       "      <td>-89.1419</td>\n",
       "      <td>A cold front moved through the region on April...</td>\n",
       "      <td>A part of Williamsville Road was flooded.</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>201404</td>\n",
       "      <td>7</td>\n",
       "      <td>230</td>\n",
       "      <td>201404</td>\n",
       "      <td>7</td>\n",
       "      <td>330</td>\n",
       "      <td>83926</td>\n",
       "      <td>507355</td>\n",
       "      <td>MISSISSIPPI</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S</td>\n",
       "      <td>OKATIBBEE LAKE</td>\n",
       "      <td>32.4900</td>\n",
       "      <td>-88.8400</td>\n",
       "      <td>32.4920</td>\n",
       "      <td>-88.8195</td>\n",
       "      <td>A cold front moved through the region on April...</td>\n",
       "      <td>Multiple secondary roads were flooded.</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  END_TIME  \\\n",
       "0            201402         18        1000         201402       18      2000   \n",
       "1            201403         30         831         201403       30       931   \n",
       "2            201404         27        2306         201404       27      2306   \n",
       "3            201404         27        2303         201404       27      2303   \n",
       "4            201402         15        1300         201402       15      2100   \n",
       "..              ...        ...         ...            ...      ...       ...   \n",
       "95           201403          6        1400         201403        7      1300   \n",
       "96           201403          6        1400         201403        7      1300   \n",
       "97           201403          9        1800         201403       11      1330   \n",
       "98           201404          7        1115         201404        7      1315   \n",
       "99           201404          7         230         201404        7       330   \n",
       "\n",
       "    EPISODE_ID  EVENT_ID          STATE  STATE_FIPS  ...  END_RANGE  \\\n",
       "0        83473    503953  NEW HAMPSHIRE          33  ...        NaN   \n",
       "1        83971    507163  MASSACHUSETTS          25  ...        1.0   \n",
       "2        83517    506236       MISSOURI          29  ...        1.0   \n",
       "3        83517    506237       MISSOURI          29  ...        1.0   \n",
       "4        83132    501499     WASHINGTON          53  ...        NaN   \n",
       "..         ...       ...            ...         ...  ...        ...   \n",
       "95       83831    506449        MONTANA          30  ...       58.0   \n",
       "96       83831    506451        MONTANA          30  ...       32.0   \n",
       "97       83831    512872        MONTANA          30  ...       29.0   \n",
       "98       83926    508171    MISSISSIPPI          28  ...        1.0   \n",
       "99       83926    507355    MISSISSIPPI          28  ...        1.0   \n",
       "\n",
       "   END_AZIMUTH       END_LOCATION BEGIN_LAT  BEGIN_LON  END_LAT   END_LON  \\\n",
       "0          NaN                NaN       NaN        NaN      NaN       NaN   \n",
       "1          WNW  CHELMSFORD CENTER   42.5861   -71.3472  42.5867  -71.3469   \n",
       "2            W                AVA   36.9500   -92.6600  36.9500  -92.6600   \n",
       "3            W                AVA   36.9500   -92.6600  36.9500  -92.6600   \n",
       "4          NaN                NaN       NaN        NaN      NaN       NaN   \n",
       "..         ...                ...       ...        ...      ...       ...   \n",
       "95         SSE            SHAWMUT   46.4838  -109.6059  45.5450 -109.2083   \n",
       "96         ESE          GREYCLIFF   46.4838  -109.6059  45.5450 -109.2083   \n",
       "97         ESE          PARK CITY   45.4200  -109.3844  45.5376 -108.3358   \n",
       "98         NNE      WILLIAMSVILLE   32.7600   -89.1400  32.7611  -89.1419   \n",
       "99           S     OKATIBBEE LAKE   32.4900   -88.8400  32.4920  -88.8195   \n",
       "\n",
       "                                    EPISODE_NARRATIVE  \\\n",
       "0   Low pressure developing south of Long Island a...   \n",
       "1   A stacked low pressure system passed south and...   \n",
       "2   A powerful storm system and a dry line produce...   \n",
       "3   A powerful storm system and a dry line produce...   \n",
       "4   A strong cold front produced strong winds for ...   \n",
       "..                                                ...   \n",
       "95  After a very cold winter resulting in area riv...   \n",
       "96  After a very cold winter resulting in area riv...   \n",
       "97  After a very cold winter resulting in area riv...   \n",
       "98  A cold front moved through the region on April...   \n",
       "99  A cold front moved through the region on April...   \n",
       "\n",
       "                                      EVENT_NARRATIVE DATA_SOURCE  \n",
       "0   Eight to twelve inches of snow fell across eas...         CSV  \n",
       "1   Boston Road was closed near Brian Road due to ...         CSV  \n",
       "2                                                 NaN         CSV  \n",
       "3   Several power poles snapped and trees blown down.         CSV  \n",
       "4   Two stations measured strong wind gusts in the...         CSV  \n",
       "..                                                ...         ...  \n",
       "95  County officials and the Montana Department of...         CSV  \n",
       "96  County officials and the Montana Department of...         CSV  \n",
       "97  County officials reported that some streams an...         CSV  \n",
       "98          A part of Williamsville Road was flooded.         CSV  \n",
       "99             Multiple secondary roads were flooded.         CSV  \n",
       "\n",
       "[100 rows x 51 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/NOAA_StormEvents/StormEvents_2014_2024.csv\",nrows=100)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61bdf90d-e7a6-4384-9072-512b4959943b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BEGIN_DT_LOC'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BEGIN_DT_LOC'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBEGIN_DT_LOC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BEGIN_DT_LOC'"
     ]
    }
   ],
   "source": [
    "df['BEGIN_DT_LOC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c914367-4381-46e6-b890-3d73718697e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fips_code</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>customers_out</th>\n",
       "      <th>run_start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1037</td>\n",
       "      <td>Coosa</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>12</td>\n",
       "      <td>2014-11-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1051</td>\n",
       "      <td>Elmore</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>7</td>\n",
       "      <td>2014-11-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1109</td>\n",
       "      <td>Pike</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-11-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1121</td>\n",
       "      <td>Talladega</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>31</td>\n",
       "      <td>2014-11-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4017</td>\n",
       "      <td>Navajo</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-11-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>19113</td>\n",
       "      <td>Linn</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-11-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>20045</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>45</td>\n",
       "      <td>2014-11-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>20091</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-11-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>20173</td>\n",
       "      <td>Sedgwick</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-11-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>20209</td>\n",
       "      <td>Wyandotte</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-11-01 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    fips_code     county    state  customers_out       run_start_time\n",
       "0        1037      Coosa  Alabama             12  2014-11-01 04:00:00\n",
       "1        1051     Elmore  Alabama              7  2014-11-01 04:00:00\n",
       "2        1109       Pike  Alabama              1  2014-11-01 04:00:00\n",
       "3        1121  Talladega  Alabama             31  2014-11-01 04:00:00\n",
       "4        4017     Navajo  Arizona              1  2014-11-01 04:00:00\n",
       "..        ...        ...      ...            ...                  ...\n",
       "95      19113       Linn     Iowa              2  2014-11-01 04:00:00\n",
       "96      20045    Douglas   Kansas             45  2014-11-01 04:00:00\n",
       "97      20091    Johnson   Kansas              2  2014-11-01 04:00:00\n",
       "98      20173   Sedgwick   Kansas              1  2014-11-01 04:00:00\n",
       "99      20209  Wyandotte   Kansas              1  2014-11-01 04:00:00\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.read_csv(\"./data/eaglei_data/eaglei_outages_2014.csv\",nrows=100)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cdff84-6553-4f30-9674-39b5fa32c976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH', 'END_DAY', 'END_TIME', 'EPISODE_ID', 'EVENT_ID', 'STATE_FIPS', 'CZ_FIPS', 'MAGNITUDE', 'BEGIN_RANGE', 'END_RANGE', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON']\n",
      "\n",
      "Categorical columns: ['STATE', 'YEAR', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_NAME', 'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT', 'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY', 'TOR_F_SCALE', 'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE', 'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_AZIMUTH', 'END_LOCATION', 'EPISODE_NARRATIVE', 'EVENT_NARRATIVE', 'DATA_SOURCE']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/NOAA_StormEvents/StormEvents_details-ftp_v1.0_d2017_c20230317.csv\",nrows=100)\n",
    "\n",
    "def classify_columns(df, categorical_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Classify DataFrame columns as numeric or categorical.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Input DataFrame\n",
    "    categorical_threshold (float): Ratio threshold for considering \n",
    "                                  numeric columns as categorical\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary with 'numeric' and 'categorical' keys containing column lists\n",
    "    \"\"\"\n",
    "    # Initialize classification dictionary\n",
    "    column_types = {\n",
    "        'numeric': [],\n",
    "        'categorical': []\n",
    "    }\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # Check dtype first\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            # Check if numeric column might actually be categorical\n",
    "            unique_ratio = df[col].nunique() / len(df[col])\n",
    "            if unique_ratio < categorical_threshold and df[col].nunique() < 50:\n",
    "                column_types['categorical'].append(col)\n",
    "            else:\n",
    "                column_types['numeric'].append(col)\n",
    "        else:\n",
    "            column_types['categorical'].append(col)\n",
    "    \n",
    "    return column_types\n",
    "\n",
    "# Example usage:\n",
    "# Assuming your DataFrame is called 'df'\n",
    "classification = classify_columns(df)\n",
    "\n",
    "print(\"Numeric columns:\", classification['numeric'])\n",
    "print(\"\\nCategorical columns:\", classification['categorical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6daaa1f9-47b2-4318-8447-658d0b0b3cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: BEGIN_YEARMONTH\n",
      "Type: int64\n",
      "Unique values: 5\n",
      "Sample values: [201704 201710 201703 201702 201706]\n",
      "\n",
      "Column: BEGIN_DAY\n",
      "Type: int64\n",
      "Unique values: 22\n",
      "Sample values: [ 6  5 16 15 29]\n",
      "\n",
      "Column: BEGIN_TIME\n",
      "Type: int64\n",
      "Unique values: 82\n",
      "Sample values: [1509  930 1749 1759 1550]\n",
      "\n",
      "Column: END_YEARMONTH\n",
      "Type: int64\n",
      "Unique values: 5\n",
      "Sample values: [201704 201710 201703 201702 201706]\n",
      "\n",
      "Column: END_DAY\n",
      "Type: int64\n",
      "Unique values: 23\n",
      "Sample values: [ 6  5 16 15 29]\n",
      "\n",
      "Column: END_TIME\n",
      "Type: int64\n",
      "Unique values: 77\n",
      "Sample values: [1509  940 1753 1900 1550]\n",
      "\n",
      "Column: EPISODE_ID\n",
      "Type: int64\n",
      "Unique values: 33\n",
      "Sample values: [113355 113459 113448 113697 113683]\n",
      "\n",
      "Column: EVENT_ID\n",
      "Type: int64\n",
      "Unique values: 100\n",
      "Sample values: [678791 679228 679268 682042 682062]\n",
      "\n",
      "Column: STATE\n",
      "Type: object\n",
      "Unique values: 17\n",
      "Sample values: ['NEW JERSEY' 'FLORIDA' 'OHIO' 'NEBRASKA' 'INDIANA']\n",
      "\n",
      "Column: STATE_FIPS\n",
      "Type: int64\n",
      "Unique values: 17\n",
      "Sample values: [34 12 39 31 18]\n",
      "\n",
      "Column: YEAR\n",
      "Type: int64\n",
      "Unique values: 1\n",
      "Sample values: [2017]\n",
      "\n",
      "Column: MONTH_NAME\n",
      "Type: object\n",
      "Unique values: 5\n",
      "Sample values: ['April' 'October' 'March' 'February' 'June']\n",
      "\n",
      "Column: EVENT_TYPE\n",
      "Type: object\n",
      "Unique values: 12\n",
      "Sample values: ['Thunderstorm Wind' 'Tornado' 'Flood' 'Hail' 'Flash Flood']\n",
      "\n",
      "Column: CZ_TYPE\n",
      "Type: object\n",
      "Unique values: 2\n",
      "Sample values: ['C' 'Z']\n",
      "\n",
      "Column: CZ_FIPS\n",
      "Type: int64\n",
      "Unique values: 43\n",
      "Sample values: [ 15  71  57  25 155]\n",
      "\n",
      "Column: CZ_NAME\n",
      "Type: object\n",
      "Unique values: 48\n",
      "Sample values: ['GLOUCESTER' 'LEE' 'GREENE' 'CLERMONT' 'CASS']\n",
      "\n",
      "Column: WFO\n",
      "Type: object\n",
      "Unique values: 12\n",
      "Sample values: ['PHI' 'TBW' 'ILN' 'OAX' 'AKQ']\n",
      "\n",
      "Column: BEGIN_DATE_TIME\n",
      "Type: object\n",
      "Unique values: 87\n",
      "Sample values: ['06-APR-17 15:09:00' '06-APR-17 09:30:00' '05-APR-17 17:49:00'\n",
      " '16-APR-17 17:59:00' '15-APR-17 15:50:00']\n",
      "\n",
      "Column: CZ_TIMEZONE\n",
      "Type: object\n",
      "Unique values: 3\n",
      "Sample values: ['EST-5' 'CST-6' 'MST-7']\n",
      "\n",
      "Column: END_DATE_TIME\n",
      "Type: object\n",
      "Unique values: 84\n",
      "Sample values: ['06-APR-17 15:09:00' '06-APR-17 09:40:00' '05-APR-17 17:53:00'\n",
      " '16-APR-17 19:00:00' '15-APR-17 15:50:00']\n",
      "\n",
      "Column: INJURIES_DIRECT\n",
      "Type: int64\n",
      "Unique values: 2\n",
      "Sample values: [0 1]\n",
      "\n",
      "Column: INJURIES_INDIRECT\n",
      "Type: int64\n",
      "Unique values: 1\n",
      "Sample values: [0]\n",
      "\n",
      "Column: DEATHS_DIRECT\n",
      "Type: int64\n",
      "Unique values: 1\n",
      "Sample values: [0]\n",
      "\n",
      "Column: DEATHS_INDIRECT\n",
      "Type: int64\n",
      "Unique values: 1\n",
      "Sample values: [0]\n",
      "\n",
      "Column: DAMAGE_PROPERTY\n",
      "Type: object\n",
      "Unique values: 7\n",
      "Sample values: [nan '110.00K' '1.00K' '5.00K' '0.00K']\n",
      "\n",
      "Column: DAMAGE_CROPS\n",
      "Type: object\n",
      "Unique values: 2\n",
      "Sample values: [nan '0.00K' '0.01K']\n",
      "\n",
      "Column: SOURCE\n",
      "Type: object\n",
      "Unique values: 19\n",
      "Sample values: ['Trained Spotter' 'Emergency Manager' 'Amateur Radio' 'Public'\n",
      " 'Law Enforcement']\n",
      "\n",
      "Column: MAGNITUDE\n",
      "Type: float64\n",
      "Unique values: 22\n",
      "Sample values: [52.   nan 50.   1.5  1. ]\n",
      "\n",
      "Column: MAGNITUDE_TYPE\n",
      "Type: object\n",
      "Unique values: 2\n",
      "Sample values: ['EG' nan 'MG']\n",
      "\n",
      "Column: FLOOD_CAUSE\n",
      "Type: object\n",
      "Unique values: 2\n",
      "Sample values: [nan 'Heavy Rain' 'Heavy Rain / Tropical System']\n",
      "\n",
      "Column: CATEGORY\n",
      "Type: float64\n",
      "Unique values: 0\n",
      "Sample values: [nan]\n",
      "\n",
      "Column: TOR_F_SCALE\n",
      "Type: object\n",
      "Unique values: 1\n",
      "Sample values: [nan 'EF0']\n",
      "\n",
      "Column: TOR_LENGTH\n",
      "Type: float64\n",
      "Unique values: 1\n",
      "Sample values: [ nan 7.43]\n",
      "\n",
      "Column: TOR_WIDTH\n",
      "Type: float64\n",
      "Unique values: 1\n",
      "Sample values: [nan 20.]\n",
      "\n",
      "Column: TOR_OTHER_WFO\n",
      "Type: float64\n",
      "Unique values: 0\n",
      "Sample values: [nan]\n",
      "\n",
      "Column: TOR_OTHER_CZ_STATE\n",
      "Type: float64\n",
      "Unique values: 0\n",
      "Sample values: [nan]\n",
      "\n",
      "Column: TOR_OTHER_CZ_FIPS\n",
      "Type: float64\n",
      "Unique values: 0\n",
      "Sample values: [nan]\n",
      "\n",
      "Column: TOR_OTHER_CZ_NAME\n",
      "Type: float64\n",
      "Unique values: 0\n",
      "Sample values: [nan]\n",
      "\n",
      "Column: BEGIN_RANGE\n",
      "Type: float64\n",
      "Unique values: 12\n",
      "Sample values: [ 1.  3.  2.  0. 12.]\n",
      "\n",
      "Column: BEGIN_AZIMUTH\n",
      "Type: object\n",
      "Unique values: 16\n",
      "Sample values: ['NW' 'S' 'NE' 'ENE' 'N']\n",
      "\n",
      "Column: BEGIN_LOCATION\n",
      "Type: object\n",
      "Unique values: 68\n",
      "Sample values: ['FRIES MILLS' 'PUNTA RASSA' 'FAIRBORN' 'SUMMERSIDE' 'COLE ARPT']\n",
      "\n",
      "Column: END_RANGE\n",
      "Type: float64\n",
      "Unique values: 12\n",
      "Sample values: [ 1.  3.  2.  0. 12.]\n",
      "\n",
      "Column: END_AZIMUTH\n",
      "Type: object\n",
      "Unique values: 16\n",
      "Sample values: ['NW' 'SW' 'NE' 'ENE' 'E']\n",
      "\n",
      "Column: END_LOCATION\n",
      "Type: object\n",
      "Unique values: 68\n",
      "Sample values: ['FRIES MILLS' 'FORT MYERS VILLAS' 'FAIRBORN' 'SUMMERSIDE' 'COLE ARPT']\n",
      "\n",
      "Column: BEGIN_LAT\n",
      "Type: float64\n",
      "Unique values: 77\n",
      "Sample values: [39.66   26.501  39.85   39.1065 40.98  ]\n",
      "\n",
      "Column: BEGIN_LON\n",
      "Type: float64\n",
      "Unique values: 73\n",
      "Sample values: [-75.08   -81.998  -83.99   -84.2875 -95.89  ]\n",
      "\n",
      "Column: END_LAT\n",
      "Type: float64\n",
      "Unique values: 77\n",
      "Sample values: [39.66   26.5339 39.85   39.1061 40.98  ]\n",
      "\n",
      "Column: END_LON\n",
      "Type: float64\n",
      "Unique values: 73\n",
      "Sample values: [-75.08   -81.8836 -83.99   -84.2874 -95.89  ]\n",
      "\n",
      "Column: EPISODE_NARRATIVE\n",
      "Type: object\n",
      "Unique values: 32\n",
      "Sample values: ['Low pressure tracked from the Ohio Valley into the Western Great Lakes with a warm front surging northward ahead of the low which was followed by a cold front.  Moisture and instability was drawn northwest ahead of the front which led to locally heavy showers and thunderstorms. Some of thunderstorms were strong to severe with gusty winds.'\n",
      " 'A line of thunderstorms developed along a prefrontal trough and moved south through the Florida Peninsula on the morning of the 6th. Some of the stronger storms produced and EF-0 tornado and one inch hail.'\n",
      " 'Showers and thunderstorms developed ahead of a strengthening surface low which moved from the Middle Mississippi Valley into Northwest Ohio.'\n",
      " 'Thunderstorms with very heavy rain developed ahead of a cold front.'\n",
      " 'An upper level storm system moved into Nebraska and Iowa on the afternoon of April 15th. This allowed for a dry line to move through southeast Nebraska with a trailing cold front moving into northeast Nebraska. Both of these boundaries served as a focus for severe weather activity. Supercells initially developed along the dry line in southeast Nebraska and moved into southwest Iowa. These thunderstorms generally produced large hail, though one tornado did occur with the initial development. Supercells then developed along the cold front in northeast Nebraska and tracked southeast, and eventually into western Iowa by late evening. These produced significant hail and wind as they tracked across the area. The severe weather threat ended by late evening as storms moved out of the area.']\n",
      "\n",
      "Column: EVENT_NARRATIVE\n",
      "Type: object\n",
      "Unique values: 80\n",
      "Sample values: ['A couple of trees were taken down due to thunderstorm wind gusts.'\n",
      " 'Emergency management reported and broadcast media received video of a tornado that crossed the southern point of Pine Island. The tornado then became a waterspout as it moved east and into Fort Myers towards Lakes Regional Park. In Fort Myers, the tornado destroyed one mobile home, damaged trees, fences, and car ports, and lifted a metal dock out of the water at Lakes Regional Park. One person sustained minor injuries.'\n",
      " 'An entire tree was uprooted in a yard on Dayton-Springfield Rd.'\n",
      " 'Garage of a home was flooded by high water.' nan]\n",
      "\n",
      "Column: DATA_SOURCE\n",
      "Type: object\n",
      "Unique values: 1\n",
      "Sample values: ['CSV']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/NOAA_StormEvents/StormEvents_details-ftp_v1.0_d2017_c20230317.csv\",nrows=100)\n",
    "\n",
    "# For detailed analysis\n",
    "for col in df.columns:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(f\"Type: {df[col].dtype}\")\n",
    "    print(f\"Unique values: {df[col].nunique()}\")\n",
    "    print(f\"Sample values: {df[col].unique()[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71df9658-77a4-4db5-9dbd-58f3b0a9447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/NOAA_StormEvents/StormEvents_2014_2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e66a1966-edcf-42fb-9d3d-25c50fd0c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_merge = pd.read_pickle(\"noaa_eaglei_merged.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d35f8ac-4ddd-42b9-883c-ae14bae139b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 100\n",
    "df_subset = df_merge[:nrows]\n",
    "df_subset.to_csv(\"noaa_eaglei_merged_subset.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
