{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c05870a-f905-4390-8266-88c0d56db13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOAA data loaded successfully.\n",
      "Performing initial cleaning and type conversions...\n",
      "\n",
      "--- Unique Timezones Found in CZ_TIMEZONE ---\n",
      "['EST-5' 'CST-6' 'PST-8' 'MST-7' 'HST-10' 'AKST-9' 'AST-4' 'GST10'\n",
      " 'SST-11' 'PDT-7' 'CDT-5' 'EDT-4']\n",
      "Number of unique timezone entries: 12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# [Previous loading code remains the same]\n",
    "# ...\n",
    "try:\n",
    "    df_noaa = pd.read_csv(noaa_file_path, low_memory=False)\n",
    "    print(\"NOAA data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {noaa_file_path}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading NOAA data: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Performing initial cleaning and type conversions...\")\n",
    "\n",
    "# --- Datetime Conversion ---\n",
    "noaa_datetime_format = '%d-%b-%y %H:%M:%S'\n",
    "df_noaa['BEGIN_DT'] = pd.to_datetime(df_noaa['BEGIN_DATE_TIME'], format=noaa_datetime_format, errors='coerce')\n",
    "df_noaa['END_DT'] = pd.to_datetime(df_noaa['END_DATE_TIME'], format=noaa_datetime_format, errors='coerce')\n",
    "\n",
    "begin_nat_count = df_noaa['BEGIN_DT'].isna().sum()\n",
    "end_nat_count = df_noaa['END_DT'].isna().sum()\n",
    "# ... (rest of initial datetime parsing checks) ...\n",
    "\n",
    "# --- *** INSPECT TIMEZONES *** ---\n",
    "print(\"\\n--- Unique Timezones Found in CZ_TIMEZONE ---\")\n",
    "unique_timezones = df_noaa['CZ_TIMEZONE'].unique()\n",
    "print(unique_timezones)\n",
    "print(f\"Number of unique timezone entries: {len(unique_timezones)}\")\n",
    "# --- *** END INSPECTION *** ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4e6e334-201f-4388-8cb8-48d6f0bacc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NOAA data from: data/NOAA_StormEvents/StormEvents_2014_2024.csv\n",
      "NOAA data loaded successfully.\n",
      "Performing initial cleaning and type conversions...\n",
      "[Timestamp('2014-02-18 10:00:00-0500', tz='America/New_York')\n",
      " Timestamp('2014-03-30 08:31:00-0400', tz='America/New_York')\n",
      " Timestamp('2014-04-27 23:06:00-0500', tz='America/Chicago') ...\n",
      " Timestamp('2024-05-09 12:53:00-0500', tz='America/Chicago')\n",
      " Timestamp('2024-05-22 18:09:00-0400', tz='America/New_York')\n",
      " Timestamp('2024-08-06 07:52:00-0400', tz='America/New_York')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Define the path to the NOAA data file\n",
    "noaa_file_path = 'data/NOAA_StormEvents/StormEvents_2014_2024.csv'\n",
    "\n",
    "# Define columns that are likely numeric but might have issues during load\n",
    "numeric_cols_to_check = [\n",
    "    'BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH', 'END_DAY', 'END_TIME',\n",
    "    'EPISODE_ID', 'EVENT_ID', 'STATE_FIPS', 'CZ_FIPS',\n",
    "    'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT', 'DEATHS_INDIRECT',\n",
    "    'MAGNITUDE', 'TOR_LENGTH', 'TOR_WIDTH',\n",
    "    'BEGIN_RANGE', 'END_RANGE', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON'\n",
    "]\n",
    "\n",
    "# Define the expected datetime format\n",
    "# Using errors='coerce' will turn unparseable dates into NaT (Not a Time)\n",
    "noaa_datetime_format = '%d-%b-%y %H:%M:%S'\n",
    "\n",
    "print(f\"Loading NOAA data from: {noaa_file_path}\")\n",
    "\n",
    "# --- Load the data ---\n",
    "# Consider using low_memory=False if dtype warnings appear, or specify dtypes more precisely\n",
    "# For very large files, consider chunking or libraries like Dask/Polars\n",
    "try:\n",
    "    df_noaa = pd.read_csv(noaa_file_path, low_memory=False)\n",
    "    print(\"NOAA data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {noaa_file_path}\")\n",
    "    # Exit or handle error appropriately\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading NOAA data: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Performing initial cleaning and type conversions...\")\n",
    "\n",
    "# --- Datetime Conversion ---\n",
    "# Convert BEGIN_DATE_TIME and END_DATE_TIME\n",
    "# errors='coerce' handles unparseable formats by setting them to NaT\n",
    "df_noaa['BEGIN_DT'] = pd.to_datetime(df_noaa['BEGIN_DATE_TIME'], format=noaa_datetime_format, errors='coerce')\n",
    "df_noaa['END_DT'] = pd.to_datetime(df_noaa['END_DATE_TIME'], format=noaa_datetime_format, errors='coerce')\n",
    "\n",
    "# Check for parsing errors (NaT values)\n",
    "begin_nat_count = df_noaa['BEGIN_DT'].isna().sum()\n",
    "end_nat_count = df_noaa['END_DT'].isna().sum()\n",
    "if begin_nat_count > 0 or end_nat_count > 0:\n",
    "    print(f\"Warning: Found {begin_nat_count} NaT values in BEGIN_DT after parsing.\")\n",
    "    print(f\"Warning: Found {end_nat_count} NaT values in END_DT after parsing.\")\n",
    "    # Consider dropping or investigating rows with NaT datetimes if they are critical\n",
    "    # df_noaa.dropna(subset=['BEGIN_DT', 'END_DT'], inplace=True)\n",
    "\n",
    "\n",
    "# --- Timezone Handling ---\n",
    "# Map common timezone abbreviations to standard Olson names usable by pandas\n",
    "# This might need expansion based on unique values in CZ_TIMEZONE\n",
    "tz_map = {\n",
    "    # Standard US Timezones (using Olson names that handle DST)\n",
    "    'EST-5': 'America/New_York',    # Eastern Time\n",
    "    'EDT-4': 'America/New_York',    # Eastern Time (Daylight)\n",
    "    'CST-6': 'America/Chicago',     # Central Time\n",
    "    'CDT-5': 'America/Chicago',     # Central Time (Daylight)\n",
    "    'MST-7': 'America/Denver',      # Mountain Time (most areas)\n",
    "    'MDT-6': 'America/Denver',      # Mountain Time (most areas - Daylight) - Added MDT just in case although not in list\n",
    "    'PST-8': 'America/Los_Angeles', # Pacific Time\n",
    "    'PDT-7': 'America/Los_Angeles', # Pacific Time (Daylight)\n",
    "    'AKST-9': 'America/Anchorage',  # Alaska Time\n",
    "    'AKDT-8': 'America/Anchorage',  # Alaska Time (Daylight) - Added AKDT just in case\n",
    "    'HST-10': 'Pacific/Honolulu',   # Hawaii Standard Time (no DST)\n",
    "\n",
    "    # Atlantic & Territories\n",
    "    'AST-4': 'America/Puerto_Rico', # Atlantic Standard Time (no DST in PR)\n",
    "    'GST10': 'Pacific/Guam',        # Guam Standard Time (UTC+10)\n",
    "    'SST-11': 'Pacific/Pago_Pago',   # Samoa Standard Time (UTC-11)\n",
    "\n",
    "    # Add mappings for any potential NaN or empty strings if they exist\n",
    "    '': None, # Map empty string explicitly if needed\n",
    "    # np.nan: None # pd.isna() check in function should handle actual NaN objects\n",
    "}\n",
    "\n",
    "# Function to apply timezone localization\n",
    "def localize_datetime(row):\n",
    "    tz_str = row['CZ_TIMEZONE']\n",
    "    dt = row['datetime_col']\n",
    "    if pd.isna(dt) or pd.isna(tz_str):\n",
    "        return pd.NaT\n",
    "\n",
    "    tz_name = tz_map.get(tz_str)\n",
    "    if tz_name:\n",
    "        try:\n",
    "            # Localize the naive datetime\n",
    "            return dt.tz_localize(tz_name, ambiguous='NaT', nonexistent='NaT')\n",
    "        except Exception as e:\n",
    "            # Log warning for specific row/error if needed\n",
    "            # warnings.warn(f\"Could not localize timezone '{tz_str}' for datetime {dt}: {e}\")\n",
    "            return pd.NaT # Failed to localize\n",
    "    else:\n",
    "        # Log warning for unmapped timezone if needed\n",
    "        # warnings.warn(f\"Timezone '{tz_str}' not found in tz_map.\")\n",
    "        return pd.NaT # Timezone not in map\n",
    "\n",
    "# Apply localization - requires iterating or a more complex apply\n",
    "# Create temporary column for the function\n",
    "df_noaa['datetime_col'] = df_noaa['BEGIN_DT']\n",
    "df_noaa['BEGIN_DT_LOC'] = df_noaa.apply(localize_datetime, axis=1)\n",
    "\n",
    "df_noaa['datetime_col'] = df_noaa['END_DT']\n",
    "df_noaa['END_DT_LOC'] = df_noaa.apply(localize_datetime, axis=1)\n",
    "\n",
    "unique_dt = df_noaa['BEGIN_DT_LOC'].unique()\n",
    "\n",
    "print(unique_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d07f51b1-e50e-480c-92ab-2feada827b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2014-02-18 10:00:00-05:00\n",
       "1         2014-03-30 08:31:00-04:00\n",
       "2         2014-04-27 23:06:00-05:00\n",
       "3         2014-04-27 23:03:00-05:00\n",
       "4         2014-02-15 13:00:00-08:00\n",
       "                    ...            \n",
       "691429    2024-05-26 11:48:00-04:00\n",
       "691430    2024-05-22 18:09:00-04:00\n",
       "691431    2024-05-22 17:57:00-04:00\n",
       "691432    2024-06-23 17:45:00-04:00\n",
       "691433    2024-08-06 07:52:00-04:00\n",
       "Name: BEGIN_DT_LOC, Length: 691434, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noaa['BEGIN_DT_LOC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f4b41b5-7eed-402e-a0ad-07e40ed1846e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NOAA data from: data/NOAA_StormEvents/StormEvents_2014_2024.csv\n",
      "NOAA data loaded successfully.\n",
      "Performing initial cleaning and type conversions...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 114\u001b[0m\n\u001b[1;32m    111\u001b[0m df_noaa\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime_col\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# remove temporary column\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Convert localized datetimes to UTC\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m df_noaa[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBEGIN_DT_UTC\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_noaa\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBEGIN_DT_LOC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241m.\u001b[39mtz_convert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    115\u001b[0m df_noaa[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEND_DT_UTC\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_noaa[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEND_DT_LOC\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_convert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Check for NaTs introduced during timezone conversion\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/generic.py:6296\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   6290\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   6291\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   6292\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   6293\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   6294\u001b[0m ):\n\u001b[1;32m   6295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 6296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/accessors.py:643\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, PeriodDtype):\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[0;32m--> 643\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Define the path to the NOAA data file\n",
    "noaa_file_path = 'data/NOAA_StormEvents/StormEvents_2014_2024.csv'\n",
    "\n",
    "# Define columns that are likely numeric but might have issues during load\n",
    "numeric_cols_to_check = [\n",
    "    'BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH', 'END_DAY', 'END_TIME',\n",
    "    'EPISODE_ID', 'EVENT_ID', 'STATE_FIPS', 'CZ_FIPS',\n",
    "    'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT', 'DEATHS_INDIRECT',\n",
    "    'MAGNITUDE', 'TOR_LENGTH', 'TOR_WIDTH',\n",
    "    'BEGIN_RANGE', 'END_RANGE', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON'\n",
    "]\n",
    "\n",
    "# Define the expected datetime format\n",
    "# Using errors='coerce' will turn unparseable dates into NaT (Not a Time)\n",
    "noaa_datetime_format = '%d-%b-%y %H:%M:%S'\n",
    "\n",
    "print(f\"Loading NOAA data from: {noaa_file_path}\")\n",
    "\n",
    "# --- Load the data ---\n",
    "# Consider using low_memory=False if dtype warnings appear, or specify dtypes more precisely\n",
    "# For very large files, consider chunking or libraries like Dask/Polars\n",
    "try:\n",
    "    df_noaa = pd.read_csv(noaa_file_path, low_memory=False)\n",
    "    print(\"NOAA data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {noaa_file_path}\")\n",
    "    # Exit or handle error appropriately\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading NOAA data: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Performing initial cleaning and type conversions...\")\n",
    "\n",
    "# --- Datetime Conversion ---\n",
    "# Convert BEGIN_DATE_TIME and END_DATE_TIME\n",
    "# errors='coerce' handles unparseable formats by setting them to NaT\n",
    "df_noaa['BEGIN_DT'] = pd.to_datetime(df_noaa['BEGIN_DATE_TIME'], format=noaa_datetime_format, errors='coerce')\n",
    "df_noaa['END_DT'] = pd.to_datetime(df_noaa['END_DATE_TIME'], format=noaa_datetime_format, errors='coerce')\n",
    "\n",
    "# Check for parsing errors (NaT values)\n",
    "begin_nat_count = df_noaa['BEGIN_DT'].isna().sum()\n",
    "end_nat_count = df_noaa['END_DT'].isna().sum()\n",
    "if begin_nat_count > 0 or end_nat_count > 0:\n",
    "    print(f\"Warning: Found {begin_nat_count} NaT values in BEGIN_DT after parsing.\")\n",
    "    print(f\"Warning: Found {end_nat_count} NaT values in END_DT after parsing.\")\n",
    "    # Consider dropping or investigating rows with NaT datetimes if they are critical\n",
    "    # df_noaa.dropna(subset=['BEGIN_DT', 'END_DT'], inplace=True)\n",
    "\n",
    "\n",
    "# --- Timezone Handling ---\n",
    "# Map common timezone abbreviations to standard Olson names usable by pandas\n",
    "# This might need expansion based on unique values in CZ_TIMEZONE\n",
    "tz_map = {\n",
    "    # Standard US Timezones (using Olson names that handle DST)\n",
    "    'EST-5': 'America/New_York',    # Eastern Time\n",
    "    'EDT-4': 'America/New_York',    # Eastern Time (Daylight)\n",
    "    'CST-6': 'America/Chicago',     # Central Time\n",
    "    'CDT-5': 'America/Chicago',     # Central Time (Daylight)\n",
    "    'MST-7': 'America/Denver',      # Mountain Time (most areas)\n",
    "    'MDT-6': 'America/Denver',      # Mountain Time (most areas - Daylight) - Added MDT just in case although not in list\n",
    "    'PST-8': 'America/Los_Angeles', # Pacific Time\n",
    "    'PDT-7': 'America/Los_Angeles', # Pacific Time (Daylight)\n",
    "    'AKST-9': 'America/Anchorage',  # Alaska Time\n",
    "    'AKDT-8': 'America/Anchorage',  # Alaska Time (Daylight) - Added AKDT just in case\n",
    "    'HST-10': 'Pacific/Honolulu',   # Hawaii Standard Time (no DST)\n",
    "\n",
    "    # Atlantic & Territories\n",
    "    'AST-4': 'America/Puerto_Rico', # Atlantic Standard Time (no DST in PR)\n",
    "    'GST10': 'Pacific/Guam',        # Guam Standard Time (UTC+10)\n",
    "    'SST-11': 'Pacific/Pago_Pago',   # Samoa Standard Time (UTC-11)\n",
    "\n",
    "    # Add mappings for any potential NaN or empty strings if they exist\n",
    "    '': None, # Map empty string explicitly if needed\n",
    "    # np.nan: None # pd.isna() check in function should handle actual NaN objects\n",
    "}\n",
    "\n",
    "# Function to apply timezone localization\n",
    "def localize_datetime(row):\n",
    "    tz_str = row['CZ_TIMEZONE']\n",
    "    dt = row['datetime_col']\n",
    "    if pd.isna(dt) or pd.isna(tz_str):\n",
    "        return pd.NaT\n",
    "\n",
    "    tz_name = tz_map.get(tz_str)\n",
    "    if tz_name:\n",
    "        try:\n",
    "            # Localize the naive datetime\n",
    "            return dt.tz_localize(tz_name, ambiguous='NaT', nonexistent='NaT')\n",
    "        except Exception as e:\n",
    "            # Log warning for specific row/error if needed\n",
    "            # warnings.warn(f\"Could not localize timezone '{tz_str}' for datetime {dt}: {e}\")\n",
    "            return pd.NaT # Failed to localize\n",
    "    else:\n",
    "        # Log warning for unmapped timezone if needed\n",
    "        # warnings.warn(f\"Timezone '{tz_str}' not found in tz_map.\")\n",
    "        return pd.NaT # Timezone not in map\n",
    "\n",
    "# Apply localization - requires iterating or a more complex apply\n",
    "# Create temporary column for the function\n",
    "df_noaa['datetime_col'] = df_noaa['BEGIN_DT']\n",
    "df_noaa['BEGIN_DT_LOC'] = df_noaa.apply(localize_datetime, axis=1)\n",
    "\n",
    "df_noaa['datetime_col'] = df_noaa['END_DT']\n",
    "df_noaa['END_DT_LOC'] = df_noaa.apply(localize_datetime, axis=1)\n",
    "\n",
    "df_noaa.drop(columns=['datetime_col'], inplace=True) # remove temporary column\n",
    "\n",
    "# Convert localized datetimes to UTC\n",
    "df_noaa['BEGIN_DT_UTC'] = df_noaa['BEGIN_DT_LOC'].dt.tz_convert('UTC')\n",
    "df_noaa['END_DT_UTC'] = df_noaa['END_DT_LOC'].dt.tz_convert('UTC')\n",
    "\n",
    "# Check for NaTs introduced during timezone conversion\n",
    "begin_tz_nat_count = df_noaa['BEGIN_DT_UTC'].isna().sum()\n",
    "end_tz_nat_count = df_noaa['END_DT_UTC'].isna().sum()\n",
    "if begin_tz_nat_count > begin_nat_count or end_tz_nat_count > end_nat_count:\n",
    "     print(f\"Warning: {begin_tz_nat_count - begin_nat_count} additional NaTs in BEGIN_DT_UTC after timezone conversion.\")\n",
    "     print(f\"Warning: {end_tz_nat_count - end_nat_count} additional NaTs in END_DT_UTC after timezone conversion.\")\n",
    "     # Consider dropping rows where timezone conversion failed if UTC time is essential\n",
    "     # df_noaa.dropna(subset=['BEGIN_DT_UTC', 'END_DT_UTC'], inplace=True)\n",
    "\n",
    "\n",
    "# --- Numeric Conversions ---\n",
    "for col in numeric_cols_to_check:\n",
    "    if col in df_noaa.columns:\n",
    "        # Convert to numeric, coercing errors to NaN\n",
    "        df_noaa[col] = pd.to_numeric(df_noaa[col], errors='coerce')\n",
    "        # Optionally fill NaNs created by coercion if appropriate (e.g., injuries/deaths)\n",
    "        if 'INJURIES' in col or 'DEATHS' in col:\n",
    "            df_noaa[col].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# --- FIPS Code to String ---\n",
    "# Convert FIPS codes to string for future consistent merging\n",
    "# Padding will be handled later when merging with Eaglei\n",
    "if 'STATE_FIPS' in df_noaa.columns:\n",
    "    df_noaa['STATE_FIPS'] = df_noaa['STATE_FIPS'].astype(str)\n",
    "if 'CZ_FIPS' in df_noaa.columns:\n",
    "    df_noaa['CZ_FIPS'] = df_noaa['CZ_FIPS'].astype(str)\n",
    "\n",
    "\n",
    "# --- Display Info and Head ---\n",
    "print(\"\\n--- NOAA DataFrame Info after initial cleaning ---\")\n",
    "df_noaa.info(verbose=True, show_counts=True)\n",
    "\n",
    "print(\"\\n--- NOAA DataFrame Head ---\")\n",
    "print(df_noaa[['EVENT_ID', 'STATE', 'CZ_TYPE', 'CZ_FIPS', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'BEGIN_DT', 'BEGIN_DT_LOC', 'BEGIN_DT_UTC']].head())\n",
    "\n",
    "# --- Optional: Check unique timezones ---\n",
    "# print(\"\\n--- Unique Timezones Found ---\")\n",
    "# print(df_noaa['CZ_TIMEZONE'].value_counts())\n",
    "\n",
    "print(\"\\nStep 1 (NOAA Load/Clean) Complete.\")\n",
    "# df_noaa now contains the loaded and initially cleaned NOAA data\n",
    "# Key new columns: BEGIN_DT, END_DT (original parsed),\n",
    "#                  BEGIN_DT_LOC, END_DT_LOC (localized),\n",
    "#                  BEGIN_DT_UTC, END_DT_UTC (converted to UTC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b33d7e51-7dd6-4e79-bf4f-633dbc9c4e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NOAA data from: data/NOAA_StormEvents/StormEvents_2014_2024.csv\n",
      "NOAA data loaded successfully.\n",
      "Performing initial cleaning and type conversions...\n",
      "Parsing original datetime strings...\n",
      "Mapping timezones...\n",
      "Applying timezone localization (this may take time)...\n",
      "Timezone localization applied.\n",
      "Attempting to convert localized columns directly to UTC...\n",
      "Direct UTC conversion attempted.\n",
      "Converting numeric columns...\n",
      "Converting FIPS codes to string...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39608/3760516150.py:138: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_noaa[col].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- NOAA DataFrame Info after initial cleaning ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 691434 entries, 0 to 691433\n",
      "Data columns (total 57 columns):\n",
      " #   Column              Non-Null Count   Dtype              \n",
      "---  ------              --------------   -----              \n",
      " 0   BEGIN_YEARMONTH     691434 non-null  int64              \n",
      " 1   BEGIN_DAY           691434 non-null  int64              \n",
      " 2   BEGIN_TIME          691434 non-null  int64              \n",
      " 3   END_YEARMONTH       691434 non-null  int64              \n",
      " 4   END_DAY             691434 non-null  int64              \n",
      " 5   END_TIME            691434 non-null  int64              \n",
      " 6   EPISODE_ID          691434 non-null  int64              \n",
      " 7   EVENT_ID            691434 non-null  int64              \n",
      " 8   STATE               691434 non-null  object             \n",
      " 9   STATE_FIPS          691434 non-null  object             \n",
      " 10  YEAR                691434 non-null  int64              \n",
      " 11  MONTH_NAME          691434 non-null  object             \n",
      " 12  EVENT_TYPE          691434 non-null  object             \n",
      " 13  CZ_TYPE             691434 non-null  object             \n",
      " 14  CZ_FIPS             691434 non-null  object             \n",
      " 15  CZ_NAME             691434 non-null  object             \n",
      " 16  WFO                 691434 non-null  object             \n",
      " 17  BEGIN_DATE_TIME     691434 non-null  object             \n",
      " 18  CZ_TIMEZONE         691434 non-null  object             \n",
      " 19  END_DATE_TIME       691434 non-null  object             \n",
      " 20  INJURIES_DIRECT     691434 non-null  int64              \n",
      " 21  INJURIES_INDIRECT   691434 non-null  int64              \n",
      " 22  DEATHS_DIRECT       691434 non-null  int64              \n",
      " 23  DEATHS_INDIRECT     691434 non-null  int64              \n",
      " 24  DAMAGE_PROPERTY     550448 non-null  object             \n",
      " 25  DAMAGE_CROPS        552275 non-null  object             \n",
      " 26  SOURCE              691434 non-null  object             \n",
      " 27  MAGNITUDE           360316 non-null  float64            \n",
      " 28  MAGNITUDE_TYPE      262379 non-null  object             \n",
      " 29  FLOOD_CAUSE         75222 non-null   object             \n",
      " 30  CATEGORY            369 non-null     float64            \n",
      " 31  TOR_F_SCALE         15641 non-null   object             \n",
      " 32  TOR_LENGTH          15641 non-null   float64            \n",
      " 33  TOR_WIDTH           15641 non-null   float64            \n",
      " 34  TOR_OTHER_WFO       2043 non-null    object             \n",
      " 35  TOR_OTHER_CZ_STATE  2043 non-null    object             \n",
      " 36  TOR_OTHER_CZ_FIPS   2043 non-null    float64            \n",
      " 37  TOR_OTHER_CZ_NAME   2043 non-null    object             \n",
      " 38  BEGIN_RANGE         425309 non-null  float64            \n",
      " 39  BEGIN_AZIMUTH       425309 non-null  object             \n",
      " 40  BEGIN_LOCATION      425309 non-null  object             \n",
      " 41  END_RANGE           425309 non-null  float64            \n",
      " 42  END_AZIMUTH         425309 non-null  object             \n",
      " 43  END_LOCATION        425309 non-null  object             \n",
      " 44  BEGIN_LAT           425309 non-null  float64            \n",
      " 45  BEGIN_LON           425309 non-null  float64            \n",
      " 46  END_LAT             425309 non-null  float64            \n",
      " 47  END_LON             425309 non-null  float64            \n",
      " 48  EPISODE_NARRATIVE   691434 non-null  object             \n",
      " 49  EVENT_NARRATIVE     547265 non-null  object             \n",
      " 50  DATA_SOURCE         691434 non-null  object             \n",
      " 51  BEGIN_DT            691434 non-null  datetime64[ns]     \n",
      " 52  END_DT              691434 non-null  datetime64[ns]     \n",
      " 53  BEGIN_DT_LOC        691397 non-null  object             \n",
      " 54  END_DT_LOC          691398 non-null  object             \n",
      " 55  BEGIN_DT_UTC        691397 non-null  datetime64[ns, UTC]\n",
      " 56  END_DT_UTC          691398 non-null  datetime64[ns, UTC]\n",
      "dtypes: datetime64[ns, UTC](2), datetime64[ns](2), float64(11), int64(13), object(29)\n",
      "memory usage: 300.7+ MB\n",
      "\n",
      "--- NOAA DataFrame Head (focus on datetimes) ---\n",
      "   EVENT_ID CZ_TIMEZONE            BEGIN_DT               BEGIN_DT_LOC  \\\n",
      "0    503953       EST-5 2014-02-18 10:00:00  2014-02-18 10:00:00-05:00   \n",
      "1    507163       EST-5 2014-03-30 08:31:00  2014-03-30 08:31:00-04:00   \n",
      "2    506236       CST-6 2014-04-27 23:06:00  2014-04-27 23:06:00-05:00   \n",
      "3    506237       CST-6 2014-04-27 23:03:00  2014-04-27 23:03:00-05:00   \n",
      "4    501499       PST-8 2014-02-15 13:00:00  2014-02-15 13:00:00-08:00   \n",
      "\n",
      "               BEGIN_DT_UTC                END_DT_UTC  \n",
      "0 2014-02-18 15:00:00+00:00 2014-02-19 01:00:00+00:00  \n",
      "1 2014-03-30 12:31:00+00:00 2014-03-30 13:31:00+00:00  \n",
      "2 2014-04-28 04:06:00+00:00 2014-04-28 04:06:00+00:00  \n",
      "3 2014-04-28 04:03:00+00:00 2014-04-28 04:03:00+00:00  \n",
      "4 2014-02-15 21:00:00+00:00 2014-02-16 05:00:00+00:00  \n",
      "\n",
      "--- Data Types of Final Datetime Columns ---\n",
      "BEGIN_DT_UTC    datetime64[ns, UTC]\n",
      "END_DT_UTC      datetime64[ns, UTC]\n",
      "dtype: object\n",
      "\n",
      "Step 1 (NOAA Load/Clean) Complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Define the path to the NOAA data file\n",
    "noaa_file_path = 'data/NOAA_StormEvents/StormEvents_2014_2024.csv'\n",
    "\n",
    "# Define columns that are likely numeric but might have issues during load\n",
    "numeric_cols_to_check = [\n",
    "    'BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH', 'END_DAY', 'END_TIME',\n",
    "    'EPISODE_ID', 'EVENT_ID', 'STATE_FIPS', 'CZ_FIPS',\n",
    "    'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT', 'DEATHS_INDIRECT',\n",
    "    'MAGNITUDE', 'TOR_LENGTH', 'TOR_WIDTH',\n",
    "    'BEGIN_RANGE', 'END_RANGE', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON'\n",
    "]\n",
    "\n",
    "# Define the expected datetime format\n",
    "# Using errors='coerce' will turn unparseable dates into NaT (Not a Time)\n",
    "noaa_datetime_format = '%d-%b-%y %H:%M:%S'\n",
    "\n",
    "print(f\"Loading NOAA data from: {noaa_file_path}\")\n",
    "\n",
    "# --- Load the data ---\n",
    "try:\n",
    "    df_noaa = pd.read_csv(noaa_file_path, low_memory=False)\n",
    "    print(\"NOAA data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {noaa_file_path}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading NOAA data: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Performing initial cleaning and type conversions...\")\n",
    "\n",
    "# --- Datetime Conversion (Initial Parsing) ---\n",
    "print(\"Parsing original datetime strings...\")\n",
    "df_noaa['BEGIN_DT'] = pd.to_datetime(df_noaa['BEGIN_DATE_TIME'], format=noaa_datetime_format, errors='coerce')\n",
    "df_noaa['END_DT'] = pd.to_datetime(df_noaa['END_DATE_TIME'], format=noaa_datetime_format, errors='coerce')\n",
    "\n",
    "# Check for initial parsing errors (NaT values)\n",
    "begin_nat_count = df_noaa['BEGIN_DT'].isna().sum()\n",
    "end_nat_count = df_noaa['END_DT'].isna().sum()\n",
    "if begin_nat_count > 0 or end_nat_count > 0:\n",
    "    print(f\"Warning: Found {begin_nat_count} NaT values in BEGIN_DT after initial parsing.\")\n",
    "    print(f\"Warning: Found {end_nat_count} NaT values in END_DT after initial parsing.\")\n",
    "\n",
    "# --- Timezone Handling ---\n",
    "print(\"Mapping timezones...\")\n",
    "# Using the tz_map confirmed from your data\n",
    "tz_map = {\n",
    "    'EST-5': 'America/New_York',\n",
    "    'EDT-4': 'America/New_York',\n",
    "    'CST-6': 'America/Chicago',\n",
    "    'CDT-5': 'America/Chicago',\n",
    "    'MST-7': 'America/Denver',\n",
    "    'MDT-6': 'America/Denver', # Keep just in case\n",
    "    'PST-8': 'America/Los_Angeles',\n",
    "    'PDT-7': 'America/Los_Angeles',\n",
    "    'AKST-9': 'America/Anchorage',\n",
    "    'AKDT-8': 'America/Anchorage', # Keep just in case\n",
    "    'HST-10': 'Pacific/Honolulu',\n",
    "    'AST-4': 'America/Puerto_Rico',\n",
    "    'GST10': 'Pacific/Guam',\n",
    "    'SST-11': 'Pacific/Pago_Pago',\n",
    "    '': None, # Map empty string explicitly if needed\n",
    "}\n",
    "\n",
    "# Function to apply timezone localization\n",
    "def localize_datetime(row):\n",
    "    tz_str = row['CZ_TIMEZONE']\n",
    "    dt = row['datetime_col']\n",
    "    if pd.isna(dt) or pd.isna(tz_str):\n",
    "        return pd.NaT\n",
    "\n",
    "    # Ensure tz_str is string and strip whitespace for lookup\n",
    "    tz_str = str(tz_str).strip()\n",
    "    tz_name = tz_map.get(tz_str)\n",
    "\n",
    "    if tz_name:\n",
    "        try:\n",
    "            return dt.tz_localize(tz_name, ambiguous='NaT', nonexistent='NaT')\n",
    "        except Exception as e:\n",
    "            # warnings.warn(f\"Could not localize timezone '{tz_str}' for datetime {dt}: {e}\")\n",
    "            return pd.NaT\n",
    "    else:\n",
    "        if tz_str: # Avoid warning for known blanks mapped to None\n",
    "             warnings.warn(f\"Timezone '{tz_str}' not found in tz_map.\", UserWarning)\n",
    "        return pd.NaT\n",
    "\n",
    "# Apply localization using the helper column\n",
    "print(\"Applying timezone localization (this may take time)...\")\n",
    "df_noaa['datetime_col'] = df_noaa['BEGIN_DT']\n",
    "df_noaa['BEGIN_DT_LOC'] = df_noaa.apply(localize_datetime, axis=1)\n",
    "\n",
    "df_noaa['datetime_col'] = df_noaa['END_DT']\n",
    "df_noaa['END_DT_LOC'] = df_noaa.apply(localize_datetime, axis=1)\n",
    "\n",
    "df_noaa.drop(columns=['datetime_col'], inplace=True)\n",
    "print(\"Timezone localization applied.\")\n",
    "\n",
    "# --- Convert Mixed Timezone 'Object' Columns Directly to UTC ---\n",
    "# This step addresses the 'dtype: object' issue after localization\n",
    "print(\"Attempting to convert localized columns directly to UTC...\")\n",
    "try:\n",
    "    # Record NaNs before conversion\n",
    "    original_loc_nan_begin = df_noaa['BEGIN_DT_LOC'].isna().sum()\n",
    "    original_loc_nan_end = df_noaa['END_DT_LOC'].isna().sum()\n",
    "\n",
    "    # Use pd.to_datetime with utc=True to handle the object column containing tz-aware objects\n",
    "    df_noaa['BEGIN_DT_UTC'] = pd.to_datetime(df_noaa['BEGIN_DT_LOC'], errors='coerce', utc=True)\n",
    "    df_noaa['END_DT_UTC'] = pd.to_datetime(df_noaa['END_DT_LOC'], errors='coerce', utc=True)\n",
    "\n",
    "    print(\"Direct UTC conversion attempted.\")\n",
    "\n",
    "    # Check for new NaNs potentially introduced\n",
    "    begin_utc_nat_count = df_noaa['BEGIN_DT_UTC'].isna().sum()\n",
    "    end_utc_nat_count = df_noaa['END_DT_UTC'].isna().sum()\n",
    "    if begin_utc_nat_count > original_loc_nan_begin or end_utc_nat_count > original_loc_nan_end:\n",
    "         print(f\"Warning: Additional NaTs potentially introduced during UTC conversion.\")\n",
    "         print(f\"         ({original_loc_nan_begin} -> {begin_utc_nat_count} NaTs in BEGIN_DT_UTC)\")\n",
    "         print(f\"         ({original_loc_nan_end} -> {end_utc_nat_count} NaTs in END_DT_UTC)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to convert localized object columns to UTC. Error: {e}\")\n",
    "    # Assign NaT if conversion fails catastrophically\n",
    "    df_noaa['BEGIN_DT_UTC'] = pd.NaT\n",
    "    df_noaa['END_DT_UTC'] = pd.NaT\n",
    "\n",
    "\n",
    "# --- Numeric Conversions ---\n",
    "print(\"Converting numeric columns...\")\n",
    "for col in numeric_cols_to_check:\n",
    "    if col in df_noaa.columns:\n",
    "        df_noaa[col] = pd.to_numeric(df_noaa[col], errors='coerce')\n",
    "        if 'INJURIES' in col or 'DEATHS' in col:\n",
    "            # Fill NaNs only for specific columns where 0 makes sense\n",
    "            df_noaa[col].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# --- FIPS Code to String ---\n",
    "print(\"Converting FIPS codes to string...\")\n",
    "if 'STATE_FIPS' in df_noaa.columns:\n",
    "    # Use .astype(str).str.split('.').str[0] to handle potential floats before converting to string\n",
    "    df_noaa['STATE_FIPS'] = df_noaa['STATE_FIPS'].astype(str).str.split('.').str[0]\n",
    "if 'CZ_FIPS' in df_noaa.columns:\n",
    "    df_noaa['CZ_FIPS'] = df_noaa['CZ_FIPS'].astype(str).str.split('.').str[0]\n",
    "\n",
    "\n",
    "# --- Display Info and Head ---\n",
    "print(\"\\n--- NOAA DataFrame Info after initial cleaning ---\")\n",
    "df_noaa.info(verbose=True, show_counts=True)\n",
    "\n",
    "print(\"\\n--- NOAA DataFrame Head (focus on datetimes) ---\")\n",
    "print(df_noaa[['EVENT_ID', 'CZ_TIMEZONE', 'BEGIN_DT', 'BEGIN_DT_LOC', 'BEGIN_DT_UTC', 'END_DT_UTC']].head())\n",
    "\n",
    "print(\"\\n--- Data Types of Final Datetime Columns ---\")\n",
    "print(df_noaa[['BEGIN_DT_UTC', 'END_DT_UTC']].dtypes)\n",
    "\n",
    "print(\"\\nStep 1 (NOAA Load/Clean) Complete.\")\n",
    "# df_noaa now contains the loaded and initially cleaned NOAA data\n",
    "# Key final columns: BEGIN_DT_UTC, END_DT_UTC (should be datetime64[ns, UTC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58423f87-7c00-4d4b-8c21-1f34b3926482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "      <th>BEGIN_DT</th>\n",
       "      <th>END_DT</th>\n",
       "      <th>BEGIN_DT_LOC</th>\n",
       "      <th>END_DT_LOC</th>\n",
       "      <th>BEGIN_DT_UTC</th>\n",
       "      <th>END_DT_UTC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201402</td>\n",
       "      <td>18</td>\n",
       "      <td>1000</td>\n",
       "      <td>201402</td>\n",
       "      <td>18</td>\n",
       "      <td>2000</td>\n",
       "      <td>83473</td>\n",
       "      <td>503953</td>\n",
       "      <td>NEW HAMPSHIRE</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low pressure developing south of Long Island a...</td>\n",
       "      <td>Eight to twelve inches of snow fell across eas...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>2014-02-18 10:00:00</td>\n",
       "      <td>2014-02-18 20:00:00</td>\n",
       "      <td>2014-02-18 10:00:00-05:00</td>\n",
       "      <td>2014-02-18 20:00:00-05:00</td>\n",
       "      <td>2014-02-18 15:00:00+00:00</td>\n",
       "      <td>2014-02-19 01:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201403</td>\n",
       "      <td>30</td>\n",
       "      <td>831</td>\n",
       "      <td>201403</td>\n",
       "      <td>30</td>\n",
       "      <td>931</td>\n",
       "      <td>83971</td>\n",
       "      <td>507163</td>\n",
       "      <td>MASSACHUSETTS</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.3469</td>\n",
       "      <td>A stacked low pressure system passed south and...</td>\n",
       "      <td>Boston Road was closed near Brian Road due to ...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>2014-03-30 08:31:00</td>\n",
       "      <td>2014-03-30 09:31:00</td>\n",
       "      <td>2014-03-30 08:31:00-04:00</td>\n",
       "      <td>2014-03-30 09:31:00-04:00</td>\n",
       "      <td>2014-03-30 12:31:00+00:00</td>\n",
       "      <td>2014-03-30 13:31:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201404</td>\n",
       "      <td>27</td>\n",
       "      <td>2306</td>\n",
       "      <td>201404</td>\n",
       "      <td>27</td>\n",
       "      <td>2306</td>\n",
       "      <td>83517</td>\n",
       "      <td>506236</td>\n",
       "      <td>MISSOURI</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>-92.6600</td>\n",
       "      <td>A powerful storm system and a dry line produce...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSV</td>\n",
       "      <td>2014-04-27 23:06:00</td>\n",
       "      <td>2014-04-27 23:06:00</td>\n",
       "      <td>2014-04-27 23:06:00-05:00</td>\n",
       "      <td>2014-04-27 23:06:00-05:00</td>\n",
       "      <td>2014-04-28 04:06:00+00:00</td>\n",
       "      <td>2014-04-28 04:06:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201404</td>\n",
       "      <td>27</td>\n",
       "      <td>2303</td>\n",
       "      <td>201404</td>\n",
       "      <td>27</td>\n",
       "      <td>2303</td>\n",
       "      <td>83517</td>\n",
       "      <td>506237</td>\n",
       "      <td>MISSOURI</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>-92.6600</td>\n",
       "      <td>A powerful storm system and a dry line produce...</td>\n",
       "      <td>Several power poles snapped and trees blown down.</td>\n",
       "      <td>CSV</td>\n",
       "      <td>2014-04-27 23:03:00</td>\n",
       "      <td>2014-04-27 23:03:00</td>\n",
       "      <td>2014-04-27 23:03:00-05:00</td>\n",
       "      <td>2014-04-27 23:03:00-05:00</td>\n",
       "      <td>2014-04-28 04:03:00+00:00</td>\n",
       "      <td>2014-04-28 04:03:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201402</td>\n",
       "      <td>15</td>\n",
       "      <td>1300</td>\n",
       "      <td>201402</td>\n",
       "      <td>15</td>\n",
       "      <td>2100</td>\n",
       "      <td>83132</td>\n",
       "      <td>501499</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A strong cold front produced strong winds for ...</td>\n",
       "      <td>Two stations measured strong wind gusts in the...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>2014-02-15 13:00:00</td>\n",
       "      <td>2014-02-15 21:00:00</td>\n",
       "      <td>2014-02-15 13:00:00-08:00</td>\n",
       "      <td>2014-02-15 21:00:00-08:00</td>\n",
       "      <td>2014-02-15 21:00:00+00:00</td>\n",
       "      <td>2014-02-16 05:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691429</th>\n",
       "      <td>202405</td>\n",
       "      <td>26</td>\n",
       "      <td>1148</td>\n",
       "      <td>202405</td>\n",
       "      <td>26</td>\n",
       "      <td>1148</td>\n",
       "      <td>192532</td>\n",
       "      <td>1188957</td>\n",
       "      <td>KENTUCKY</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>-84.7200</td>\n",
       "      <td>A strong storm system moved across the Ohio an...</td>\n",
       "      <td>A trained spotter estimated 60 mph wind gusts ...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>2024-05-26 11:48:00</td>\n",
       "      <td>2024-05-26 11:48:00</td>\n",
       "      <td>2024-05-26 11:48:00-04:00</td>\n",
       "      <td>2024-05-26 11:48:00-04:00</td>\n",
       "      <td>2024-05-26 15:48:00+00:00</td>\n",
       "      <td>2024-05-26 15:48:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691430</th>\n",
       "      <td>202405</td>\n",
       "      <td>22</td>\n",
       "      <td>1809</td>\n",
       "      <td>202405</td>\n",
       "      <td>22</td>\n",
       "      <td>1809</td>\n",
       "      <td>192530</td>\n",
       "      <td>1188234</td>\n",
       "      <td>INDIANA</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>-85.7364</td>\n",
       "      <td>A cold front moved into the Ohio Valley during...</td>\n",
       "      <td>A tree was down at Lovers Lane and Prewitt Lane.</td>\n",
       "      <td>CSV</td>\n",
       "      <td>2024-05-22 18:09:00</td>\n",
       "      <td>2024-05-22 18:09:00</td>\n",
       "      <td>2024-05-22 18:09:00-04:00</td>\n",
       "      <td>2024-05-22 18:09:00-04:00</td>\n",
       "      <td>2024-05-22 22:09:00+00:00</td>\n",
       "      <td>2024-05-22 22:09:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691431</th>\n",
       "      <td>202405</td>\n",
       "      <td>22</td>\n",
       "      <td>1757</td>\n",
       "      <td>202405</td>\n",
       "      <td>22</td>\n",
       "      <td>1757</td>\n",
       "      <td>192530</td>\n",
       "      <td>1188232</td>\n",
       "      <td>INDIANA</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>-86.7247</td>\n",
       "      <td>A cold front moved into the Ohio Valley during...</td>\n",
       "      <td>A tree was reported down over Chestnut Grove R...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>2024-05-22 17:57:00</td>\n",
       "      <td>2024-05-22 17:57:00</td>\n",
       "      <td>2024-05-22 17:57:00-04:00</td>\n",
       "      <td>2024-05-22 17:57:00-04:00</td>\n",
       "      <td>2024-05-22 21:57:00+00:00</td>\n",
       "      <td>2024-05-22 21:57:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691432</th>\n",
       "      <td>202406</td>\n",
       "      <td>23</td>\n",
       "      <td>1745</td>\n",
       "      <td>202406</td>\n",
       "      <td>23</td>\n",
       "      <td>1750</td>\n",
       "      <td>191388</td>\n",
       "      <td>1192879</td>\n",
       "      <td>NEW HAMPSHIRE</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>-70.8400</td>\n",
       "      <td>A supercell thunderstorm developed across sout...</td>\n",
       "      <td>A supercell thunderstorm dropped hail the size...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>2024-06-23 17:45:00</td>\n",
       "      <td>2024-06-23 17:50:00</td>\n",
       "      <td>2024-06-23 17:45:00-04:00</td>\n",
       "      <td>2024-06-23 17:50:00-04:00</td>\n",
       "      <td>2024-06-23 21:45:00+00:00</td>\n",
       "      <td>2024-06-23 21:50:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691433</th>\n",
       "      <td>202408</td>\n",
       "      <td>6</td>\n",
       "      <td>752</td>\n",
       "      <td>202408</td>\n",
       "      <td>6</td>\n",
       "      <td>852</td>\n",
       "      <td>195694</td>\n",
       "      <td>1214246</td>\n",
       "      <td>GEORGIA</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.1375</td>\n",
       "      <td>Debby first developed into a tropical storm ab...</td>\n",
       "      <td>A Chatham County emergency manager reported a ...</td>\n",
       "      <td>CSV</td>\n",
       "      <td>2024-08-06 07:52:00</td>\n",
       "      <td>2024-08-06 08:52:00</td>\n",
       "      <td>2024-08-06 07:52:00-04:00</td>\n",
       "      <td>2024-08-06 08:52:00-04:00</td>\n",
       "      <td>2024-08-06 11:52:00+00:00</td>\n",
       "      <td>2024-08-06 12:52:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691434 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  \\\n",
       "0                201402         18        1000         201402       18   \n",
       "1                201403         30         831         201403       30   \n",
       "2                201404         27        2306         201404       27   \n",
       "3                201404         27        2303         201404       27   \n",
       "4                201402         15        1300         201402       15   \n",
       "...                 ...        ...         ...            ...      ...   \n",
       "691429           202405         26        1148         202405       26   \n",
       "691430           202405         22        1809         202405       22   \n",
       "691431           202405         22        1757         202405       22   \n",
       "691432           202406         23        1745         202406       23   \n",
       "691433           202408          6         752         202408        6   \n",
       "\n",
       "        END_TIME  EPISODE_ID  EVENT_ID          STATE STATE_FIPS  ...  \\\n",
       "0           2000       83473    503953  NEW HAMPSHIRE         33  ...   \n",
       "1            931       83971    507163  MASSACHUSETTS         25  ...   \n",
       "2           2306       83517    506236       MISSOURI         29  ...   \n",
       "3           2303       83517    506237       MISSOURI         29  ...   \n",
       "4           2100       83132    501499     WASHINGTON         53  ...   \n",
       "...          ...         ...       ...            ...        ...  ...   \n",
       "691429      1148      192532   1188957       KENTUCKY         21  ...   \n",
       "691430      1809      192530   1188234        INDIANA         18  ...   \n",
       "691431      1757      192530   1188232        INDIANA         18  ...   \n",
       "691432      1750      191388   1192879  NEW HAMPSHIRE         33  ...   \n",
       "691433       852      195694   1214246        GEORGIA         13  ...   \n",
       "\n",
       "        END_LON                                  EPISODE_NARRATIVE  \\\n",
       "0           NaN  Low pressure developing south of Long Island a...   \n",
       "1      -71.3469  A stacked low pressure system passed south and...   \n",
       "2      -92.6600  A powerful storm system and a dry line produce...   \n",
       "3      -92.6600  A powerful storm system and a dry line produce...   \n",
       "4           NaN  A strong cold front produced strong winds for ...   \n",
       "...         ...                                                ...   \n",
       "691429 -84.7200  A strong storm system moved across the Ohio an...   \n",
       "691430 -85.7364  A cold front moved into the Ohio Valley during...   \n",
       "691431 -86.7247  A cold front moved into the Ohio Valley during...   \n",
       "691432 -70.8400  A supercell thunderstorm developed across sout...   \n",
       "691433 -81.1375  Debby first developed into a tropical storm ab...   \n",
       "\n",
       "                                          EVENT_NARRATIVE DATA_SOURCE  \\\n",
       "0       Eight to twelve inches of snow fell across eas...         CSV   \n",
       "1       Boston Road was closed near Brian Road due to ...         CSV   \n",
       "2                                                     NaN         CSV   \n",
       "3       Several power poles snapped and trees blown down.         CSV   \n",
       "4       Two stations measured strong wind gusts in the...         CSV   \n",
       "...                                                   ...         ...   \n",
       "691429  A trained spotter estimated 60 mph wind gusts ...         CSV   \n",
       "691430   A tree was down at Lovers Lane and Prewitt Lane.         CSV   \n",
       "691431  A tree was reported down over Chestnut Grove R...         CSV   \n",
       "691432  A supercell thunderstorm dropped hail the size...         CSV   \n",
       "691433  A Chatham County emergency manager reported a ...         CSV   \n",
       "\n",
       "                  BEGIN_DT              END_DT               BEGIN_DT_LOC  \\\n",
       "0      2014-02-18 10:00:00 2014-02-18 20:00:00  2014-02-18 10:00:00-05:00   \n",
       "1      2014-03-30 08:31:00 2014-03-30 09:31:00  2014-03-30 08:31:00-04:00   \n",
       "2      2014-04-27 23:06:00 2014-04-27 23:06:00  2014-04-27 23:06:00-05:00   \n",
       "3      2014-04-27 23:03:00 2014-04-27 23:03:00  2014-04-27 23:03:00-05:00   \n",
       "4      2014-02-15 13:00:00 2014-02-15 21:00:00  2014-02-15 13:00:00-08:00   \n",
       "...                    ...                 ...                        ...   \n",
       "691429 2024-05-26 11:48:00 2024-05-26 11:48:00  2024-05-26 11:48:00-04:00   \n",
       "691430 2024-05-22 18:09:00 2024-05-22 18:09:00  2024-05-22 18:09:00-04:00   \n",
       "691431 2024-05-22 17:57:00 2024-05-22 17:57:00  2024-05-22 17:57:00-04:00   \n",
       "691432 2024-06-23 17:45:00 2024-06-23 17:50:00  2024-06-23 17:45:00-04:00   \n",
       "691433 2024-08-06 07:52:00 2024-08-06 08:52:00  2024-08-06 07:52:00-04:00   \n",
       "\n",
       "                       END_DT_LOC              BEGIN_DT_UTC  \\\n",
       "0       2014-02-18 20:00:00-05:00 2014-02-18 15:00:00+00:00   \n",
       "1       2014-03-30 09:31:00-04:00 2014-03-30 12:31:00+00:00   \n",
       "2       2014-04-27 23:06:00-05:00 2014-04-28 04:06:00+00:00   \n",
       "3       2014-04-27 23:03:00-05:00 2014-04-28 04:03:00+00:00   \n",
       "4       2014-02-15 21:00:00-08:00 2014-02-15 21:00:00+00:00   \n",
       "...                           ...                       ...   \n",
       "691429  2024-05-26 11:48:00-04:00 2024-05-26 15:48:00+00:00   \n",
       "691430  2024-05-22 18:09:00-04:00 2024-05-22 22:09:00+00:00   \n",
       "691431  2024-05-22 17:57:00-04:00 2024-05-22 21:57:00+00:00   \n",
       "691432  2024-06-23 17:50:00-04:00 2024-06-23 21:45:00+00:00   \n",
       "691433  2024-08-06 08:52:00-04:00 2024-08-06 11:52:00+00:00   \n",
       "\n",
       "                      END_DT_UTC  \n",
       "0      2014-02-19 01:00:00+00:00  \n",
       "1      2014-03-30 13:31:00+00:00  \n",
       "2      2014-04-28 04:06:00+00:00  \n",
       "3      2014-04-28 04:03:00+00:00  \n",
       "4      2014-02-16 05:00:00+00:00  \n",
       "...                          ...  \n",
       "691429 2024-05-26 15:48:00+00:00  \n",
       "691430 2024-05-22 22:09:00+00:00  \n",
       "691431 2024-05-22 21:57:00+00:00  \n",
       "691432 2024-06-23 21:50:00+00:00  \n",
       "691433 2024-08-06 12:52:00+00:00  \n",
       "\n",
       "[691434 rows x 57 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noaa.to_csv(\"NOAA_timezone_cleaned.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
